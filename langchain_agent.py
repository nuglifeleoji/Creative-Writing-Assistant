import os
import subprocess
import json
from typing import Dict, Any

# ç¡®ä¿ä½ å·²ç»å®‰è£…äº†ä»¥ä¸‹åº“
# pip install langchain langchain-openai

# æ³¨æ„é…ç½®OPENAI_API_KEYä»¥åŠgraphragæ‰€åœ¨è·¯å¾„(ä»£ç ç¬¬172è¡Œ)

from dotenv import load_dotenv

load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")



from langchain.agents import tool
from langchain.agents import create_react_agent, AgentExecutor, create_tool_calling_agent
from langchain import hub
from langchain_openai import ChatOpenAI,AzureChatOpenAI

# --- ç¬¬ä¸€æ­¥ï¼šå°è£… GraphRAG æŸ¥è¯¢çš„åç«¯ ---
# è¿™éƒ¨åˆ†ç›´æ¥é‡‡ç”¨äº†ä½ æä¾›çš„ä»£ç ï¼Œç”¨äºæ‰§è¡Œ GraphRAG å‘½ä»¤è¡ŒæŸ¥è¯¢
class GraphAnalysisAgent:
    def __init__(self, rag_root: str):
        self.rag_root = rag_root

    def run_graphrag_query(self, method: str, query: str) -> Dict[str, Any]:
        """é€šè¿‡å‘½ä»¤è¡Œè¿è¡Œ GraphRAG æŸ¥è¯¢ï¼Œå¹¶è¿”å›ç»“æœã€‚"""
        try:
            cmd = [
                "graphrag", "query",
                "--root", self.rag_root,
                "--method", method,
                "--query", query
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=os.getcwd(),
                check=True
            )
            
            return {
                "method": method,
                "query": query,
                "result": result.stdout,
                "success": True
            }
        except subprocess.CalledProcessError as e:
            return {
                "method": method,
                "query": query,
                "error": e.stderr,
                "success": False
            }
        except Exception as e:
            return {
                "method": method,
                "query": query,
                "error": f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}",
                "success": False
            }

    def get_characters(self) -> Dict[str, Any]:
        """è·å–æ•…äº‹ä¸­çš„æ‰€æœ‰äººç‰©è§’è‰²ã€‚"""
        query = "åˆ—å‡ºæ•…äº‹ä¸­çš„æ‰€æœ‰äººç‰©è§’è‰²"
        return self.run_graphrag_query("global", query)
    
    def get_relationships(self, p1: str, p2: str) -> Dict[str, Any]:
        """è·å–ä¸¤ä¸ªç‰¹å®šäººç‰©ä¹‹é—´çš„å…³ç³»ã€‚"""
        query = f"åˆ†æ{p1}å’Œ{p2}ä¹‹é—´çš„å…³ç³»"
        return self.run_graphrag_query("local", query)
    
    def get_important_locations(self) -> Dict[str, Any]:
        """è·å–æ•…äº‹ä¸­çš„é‡è¦åœ°ç‚¹ã€‚"""
        query = "åˆ†ææ•…äº‹ä¸­çš„é‡è¦åœ°ç‚¹å’Œåœºæ™¯"
        return self.run_graphrag_query("global", query)
    
    def background_knowledge(self) -> Dict[str, Any]:
        """è·å–æ•…äº‹çš„èƒŒæ™¯çŸ¥è¯†å’Œä¸»è¦æƒ…èŠ‚ã€‚"""
        query = "åˆ†ææ•…äº‹çš„èƒŒæ™¯çŸ¥è¯†å’Œä¸»è¦æƒ…èŠ‚"
        return self.run_graphrag_query("global", query)
    
    def local_search_query(self, query: str) -> Dict[str, Any]:
        """è¿›è¡Œè‡ªå®šä¹‰ local_search æŸ¥è¯¢ã€‚"""
        return self.run_graphrag_query("local", query)
    
    def global_search_query(self, query: str) -> Dict[str, Any]:
        """è¿›è¡Œè‡ªå®šä¹‰ global_search æŸ¥è¯¢ã€‚"""
        return self.run_graphrag_query("global", query)

# --- ç¬¬äºŒæ­¥ï¼šåˆ›å»º LangChain Agent ---
def create_graphrag_agent(graphrag_agent_instance: GraphAnalysisAgent) -> AgentExecutor:
    """
    åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªå¯ä»¥è°ƒç”¨ GraphRAG å‘½ä»¤è¡ŒåŠŸèƒ½çš„ LangChain Agentã€‚
    """
    # ä½¿ç”¨ @tool è£…é¥°å™¨ï¼Œå°† GraphAnalysisAgent çš„æ–¹æ³•åŒ…è£…æˆ LangChain å·¥å…·
    # æ³¨æ„ï¼šè¿™é‡Œçš„å·¥å…·å‡½æ•°éœ€è¦èƒ½å¤Ÿè¢« Agent ç›´æ¥è°ƒç”¨ï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨é—­åŒ…æ¥ä¼ é€’å®ä¾‹
    @tool
    def get_characters_tool() -> str:
        """ä½¿ç”¨ GraphRAG çš„å…¨å±€æŸ¥è¯¢åŠŸèƒ½è·å–æ•…äº‹ä¸­çš„æ‰€æœ‰äººç‰©è§’è‰²ã€‚"""
        result = graphrag_agent_instance.get_characters()
        return json.dumps(result, ensure_ascii=False)

    @tool
    def get_relationships_tool(p1: str, p2: str) -> str:
        """ä½¿ç”¨ GraphRAG çš„å±€éƒ¨æŸ¥è¯¢åŠŸèƒ½ï¼Œè·å–ä¸¤ä¸ªç‰¹å®šäººç‰©ä¹‹é—´çš„å…³ç³»ã€‚è¾“å…¥å‚æ•°p1å’Œp2æ˜¯äººç‰©åç§°ã€‚"""
        result = graphrag_agent_instance.get_relationships(p1, p2)
        return json.dumps(result, ensure_ascii=False)

    @tool
    def get_important_locations_tool() -> str:
        """ä½¿ç”¨ GraphRAG çš„å…¨å±€æŸ¥è¯¢åŠŸèƒ½è·å–æ•…äº‹ä¸­çš„é‡è¦åœ°ç‚¹ã€‚"""
        result = graphrag_agent_instance.get_important_locations()
        return json.dumps(result, ensure_ascii=False)

    @tool
    def background_knowledge_tool() -> str:
        """ä½¿ç”¨ GraphRAG çš„å…¨å±€æŸ¥è¯¢åŠŸèƒ½è·å–æ•…äº‹çš„èƒŒæ™¯çŸ¥è¯†ã€‚"""
        result = graphrag_agent_instance.background_knowledge()
        return json.dumps(result, ensure_ascii=False)
    
    @tool
    def local_search_tool(query: str) -> str:
        """ä½¿ç”¨ GraphRAG çš„å±€éƒ¨æŸ¥è¯¢åŠŸèƒ½è¿›è¡Œè‡ªå®šä¹‰æœç´¢ã€‚è¾“å…¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²å½¢å¼çš„æŸ¥è¯¢ã€‚"""
        result = graphrag_agent_instance.local_search_query(query)
        return json.dumps(result, ensure_ascii=False)

    @tool
    def global_search_tool(query: str) -> str:
        """ä½¿ç”¨ GraphRAG çš„å…¨å±€æŸ¥è¯¢åŠŸèƒ½è¿›è¡Œè‡ªå®šä¹‰æœç´¢ã€‚è¾“å…¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²å½¢å¼çš„æŸ¥è¯¢ã€‚"""
        result = graphrag_agent_instance.global_search_query(query)
        return json.dumps(result, ensure_ascii=False)

    # å°†æ‰€æœ‰å·¥å…·æ”¾å…¥ä¸€ä¸ªåˆ—è¡¨ä¸­
    tools = [
        get_characters_tool,
        get_relationships_tool,
        get_important_locations_tool,
        background_knowledge_tool,
        local_search_tool,
        global_search_tool
    ]

    # åˆå§‹åŒ– LLM
    # ç¡®ä¿ä½ å·²ç»è®¾ç½®äº† OPENAI_API_KEY ç¯å¢ƒå˜é‡
    llm = AzureChatOpenAI(
        openai_api_version="2024-12-01-preview",
        azure_deployment="gpt-4o-mini",
        model_name="gpt-4o-mini",
        azure_endpoint="https://tcamp.openai.azure.com/",  # ğŸ‘ˆ å°† openai_api_base æ›¿æ¢ä¸º azure_endpoint
        openai_api_key=api_key,
        temperature=0.3
    )

    # ä» LangChain Hub è·å– ReAct æç¤ºæ¨¡æ¿
    prompt = hub.pull("hwchase17/openai-tools-agent")

    # åˆ›å»º Agent
    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)

    # åˆ›å»º Agent æ‰§è¡Œå™¨
    return AgentExecutor(agent=agent, tools=tools, verbose=True)

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    # åˆå§‹åŒ–ä½ çš„ GraphAnalysisAgentï¼Œä¼ å…¥ GraphRAG é¡¹ç›®çš„æ ¹ç›®å½•
    graph_agent = GraphAnalysisAgent(rag_root="/home/grass8cow/qcd")

    # ä½¿ç”¨è¿™ä¸ªå®ä¾‹åˆ›å»º LangChain Agent
    agent_executor = create_graphrag_agent(graph_agent)

    print("LangChain Agent with GraphRAG CLI tools is ready. Type 'exit' to quit.")
    
    while True:
        user_query = input("\nè¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
        if user_query.lower() == 'exit':
            break
        
        try:
            # è°ƒç”¨ Agent æ‰§è¡Œå™¨
            response = agent_executor.invoke({"input": user_query})
            print("\n--- Agent å›ç­” ---")
            print(response["output"])
            print("--------------------\n")
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯ï¼š{e}")
            break